# 流摹 (LiuMo) 后端架构规划方案 V8.0

> **版本**: V8.0
> **状态**: 待审阅
> **日期**: 2026-01-30

---

## 一、目标与范围

### 1.1 项目背景
流摹是一个专注于中国古诗文的应用，需要支持复杂的排版渲染（网格布局、流式布局、古文排版）和高性能全文搜索。

### 1.2 本方案范围
- 数据库 Schema 设计（SQLite）
- 数据管道 ETL 流程（精选集 + 全量版）
- 后端 Rust 代码架构（Tauri）
- FTS5 全文搜索实现
- 前端数据接口适配

### 1.3 核心目标
1. **数据统一**：精选集与全量版采用统一的 JSON Schema
2. **排版支持**：支持网格布局（GRID_STANDARD）、流式布局（FLOW_VARYING）、居中对齐（CENTER_ALIGNED）
3. **高性能搜索**：基于 SQLite FTS5 的毫秒级全文检索
4. **架构精简**：删除冗余字段，数据零冗余

---

## 二、数据源分析

### 2.1 现有数据目录结构

```
liumo-assets-prep/
├── assets/
│   ├── dist/              # 精选集（已完成结构化）
│   │   ├── k12.json       # K12必背诗词 (133KB, 约150条)
│   │   ├── tang_300.json  # 唐诗三百首 (411KB, 约300条)
│   │   ├── song_300.json  # 宋词三百首 (404KB, 约300条)
│   │   ├── shijing.json   # 诗经 (178KB)
│   │   ├── wudai.json     # 花间集 (178KB)
│   │   ├── nalan.json     # 纳兰性德 (51KB)
│   │   └── caocao.json    # 曹操集 (15KB)
│   │
│   ├── raw/               # 全量源数据（需处理）
│   │   ├── tang_shi.json  # 唐诗 (约55,000条，需清洗)
│   │   ├── song_shi.json  # 宋诗
│   │   ├── song_ci.json   # 宋词
│   │   ├── gu_wen.json    # 古文
│   │   ├── qing_wen.json  # 清文（含特殊格式）
│   │   └── ...
│   │
│   ├── indices/           # 索引文件
│   │   ├── k12_index.json
│   │   ├── tang300_index.json
│   │   └── song300_index.json
│   │
│   └── patches/           # 补丁文件
│       └── manual_supplement.json
│
└── data/
    └── dist/              # 临时目录（可删除）
```

### 2.2 精选集数据格式（已完成）

`assets/dist/*.json` 已完成结构化，格式如下：

```json
{
  "title": "静夜思",
  "author": "李白",
  "dynasty": "唐",
  "content": "床前明月光，疑是地上霜。\n举头望明月，低头思故乡。",
  "type": "乐府",
  "tags": ["K12", "shi", "乐府"],
  "source": "k12",
  "original_title": "静夜思",
  "layout_strategy": "CENTER_ALIGNED",
  "content_json": "{\"paragraphs\": [{\"type\": \"main\", \"lines\": [\"床前明月光，疑是地上霜。\", \"举头望明月，低头思故乡。\"]}]}",
  "display_content": "床前明月光，疑是地上霜。\n举头望明月，低头思故乡。"
}
```

### 2.3 原始数据格式（待处理）

`assets/raw/*.json` 为原始格式：

```json
{
  "id": "08e41396-2809-423d-9bbc-1e6fb24c0ca1",
  "title": "日诗",
  "author": "宋太祖",
  "dynasty": "唐",
  "content": ["欲出未出光辣达，千山万山如火发。", "须臾走向天上来，逐却残星赶却月。"],
  "type": "shi",
  "source": "chinese-poetry"
}
```

### 2.4 数据质量问题

| 问题类型 | 文件 | 描述 | 处理方案 |
| -------- | ---- | ---- | -------- |
| 朝代错误 | tang_shi.json | 宋太祖的诗被标为"唐" | 需根据 author 反查 dynasty |
| author 前缀 | gu_wen.json | "先秦：左丘明" 含前缀 | 字符串清洗 |
| content 格式不统一 | manual_supplement.json | 纯字符串，非数组 | 统一转为字符串格式 |
| 评语格式 | qing_wen.json | 正文后接 "评: xxx" | 暂不处理，人工标注 |

---

## 三、JSON Schema 设计 (V8.0)

### 3.1 统一数据结构

```json
{
  "id": "a3f2b8c1d4e5f678",          // SHA256(title|author).substring(0, 16)
  "title": "静夜思",                 // 标题
  "author": "李白",                  // 作者（清洗后）
  "dynasty": "唐",                   // 朝代（清洗后）

  "layout_strategy": "CENTER_ALIGNED", // 布局策略
  "content_json": "{...}",            // 结构化内容（JSON String）

  "tags": ["K12", "shi", "乐府"],    // 标签数组
  "search_text": "床前明月光疑是地上霜举头望明月低头思故乡" // 搜索文本（无标点）
}
```

### 3.2 content_json 结构定义

```typescript
interface Paragraph {
  type: 'main' | 'small' | 'indent';  // 段落类型
  lines: string[];                    // 诗行数组
}

interface StructuredContent {
  paragraphs: Paragraph[];            // 段落数组
}
```

**示例**：
```json
{
  "content_json": {
    "paragraphs": [
      {
        "type": "main",
        "lines": ["床前明月光，疑是地上霜。", "举头望明月，低头思故乡。"]
      }
    ]
  }
}
```

### 3.3 layout_strategy 枚举

| 值 | 描述 | 适用场景 |
| -- | ---- | -------- |
| `GRID_STANDARD` | 标准网格 | 绝句/律诗（5言/7言，行数固定） |
| `FLOW_VARYING` | 流式布局 | 词/曲/赋（行长不固定） |
| `CENTER_ALIGNED` | 居中对齐 | 古文/杂言（散文体） |

---

## 四、数据库 Schema (SQLite)

### 4.1 主表 poetry

```sql
CREATE TABLE poetry (
    -- 主键：确定性哈希 ID
    id TEXT PRIMARY KEY,

    -- 元数据
    title TEXT NOT NULL,
    author TEXT NOT NULL,
    dynasty TEXT NOT NULL,

    -- 排版数据（必填）
    layout_strategy TEXT NOT NULL,
    content_json TEXT NOT NULL,

    -- 辅助数据
    tags TEXT,                      -- JSON 数组
    search_text TEXT NOT NULL       -- 搜索索引
);
```

### 4.2 FTS5 全文搜索虚拟表

```sql
CREATE VIRTUAL TABLE poetry_fts USING fts5(
    title,
    author,
    search_text,
    content='poetry',
    content_rowid='rowid'
);
```

### 4.3 触发器（自动同步索引）

```sql
-- 插入同步
CREATE TRIGGER poetry_ai AFTER INSERT ON poetry BEGIN
    INSERT INTO poetry_fts(rowid, title, author, search_text)
    VALUES (new.rowid, new.title, new.author, new.search_text);
END;

-- 删除同步
CREATE TRIGGER poetry_ad AFTER DELETE ON poetry BEGIN
    DELETE FROM poetry_fts WHERE rowid = old.rowid;
END;

-- 更新同步
CREATE TRIGGER poetry_au AFTER UPDATE ON poetry BEGIN
    DELETE FROM poetry_fts WHERE rowid = old.rowid;
    INSERT INTO poetry_fts(rowid, title, author, search_text)
    VALUES (new.rowid, new.title, new.author, new.search_text);
END;
```

### 4.4 索引优化

```sql
CREATE INDEX idx_dynasty ON poetry(dynasty);
CREATE INDEX idx_tags ON poetry(tags);
```

---

## 五、数据管道 ETL 设计

### 5.1 混合处理策略

| 数据集 | 处理方式 | 理由 |
| ------ | -------- | ---- |
| 精选集 (`assets/dist/`) | 直接使用现有数据 | 已完成结构化，质量最高 |
| K12/Tang300/Song300 | 使用精选集数据覆盖 | 用户高频使用，质量优先 |
| 全量剩余 | 脚本启发式处理 | 40万+ 条数据，全 AI 不现实 |

### 5.2 脚本处理流程

```python
def process_raw_file(input_path, output_path):
    """处理单个 raw 文件"""

    # 1. 读取原始数据
    with open(input_path, 'r', encoding='utf-8') as f:
        data = json.load(f)

    results = []

    for item in data:
        # 2. 清洗 author（删除前缀）
        author = clean_author(item['author'])

        # 3. 统一 content 格式
        content = normalize_content(item['content'])

        # 4. 生成 content_json
        content_json = build_content_json(content)

        # 5. 推断 layout_strategy
        layout_strategy = infer_layout_strategy(item.get('type'), content)

        # 6. 生成 tags
        tags = build_tags(item.get('type'), item.get('source'))

        # 7. 生成 search_text
        search_text = build_search_text(content)

        # 8. 生成确定性 ID
        id = generate_id(item['title'], author)

        results.append({
            "id": id,
            "title": item['title'],
            "author": author,
            "dynasty": item['dynasty'],
            "layout_strategy": layout_strategy,
            "content_json": json.dumps(content_json, ensure_ascii=False),
            "tags": tags,
            "search_text": search_text
        })

    # 9. 输出 JSON
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
```

### 5.3 核心处理函数

#### 5.3.1 clean_author()
```python
def clean_author(author: str) -> str:
    """删除 author 字段的前缀"""
    # 示例："先秦：左丘明" -> "左丘明"
    if '：' in author:
        return author.split('：')[-1].strip()
    if ':' in author:
        return author.split(':')[-1].strip()
    return author.strip()
```

#### 5.3.2 normalize_content()
```python
def normalize_content(content) -> str:
    """统一 content 格式：数组 -> 字符串"""
    if isinstance(content, list):
        return '\n'.join(content)
    return content.strip()
```

#### 5.3.3 build_content_json()
```python
def build_content_json(content: str) -> dict:
    """根据换行符构建 paragraphs 结构"""
    lines = [line.strip() for line in content.split('\n') if line.strip()]
    return {
        "paragraphs": [
            {"type": "main", "lines": lines}
        ]
    }
```

#### 5.3.4 infer_layout_strategy()
```python
def infer_layout_strategy(type_hint: str, content: str) -> str:
    """推断布局策略"""

    # 词牌优先
    if type_hint in ['ci', 'qu']:
        return 'FLOW_VARYING'

    # 根据行数和每行字数判断
    lines = content.split('\n')
    if len(lines) == 0:
        return 'CENTER_ALIGNED'

    char_counts = [len(line) for line in lines]

    # 五言绝句
    if len(lines) == 4 and all(c == 5 for c in char_counts):
        return 'GRID_STANDARD'

    # 七言绝句
    if len(lines) == 4 and all(c == 7 for c in char_counts):
        return 'GRID_STANDARD'

    # 五言律诗
    if len(lines) == 8 and all(c == 5 for c in char_counts):
        return 'GRID_STANDARD'

    # 七言律诗
    if len(lines) == 8 and all(c == 7 for c in char_counts):
        return 'GRID_STANDARD'

    # 默认流式
    return 'FLOW_VARYING'
```

#### 5.3.5 generate_id()
```python
import hashlib

def generate_id(title: str, author: str) -> str:
    """生成确定性 ID：SHA256(title|author).substring(0, 16)"""
    raw = f"{title.strip()}|{author.strip()}"
    return hashlib.sha256(raw.encode()).hexdigest()[:16]
```

#### 5.3.6 build_search_text()
```python
import re

def build_search_text(content: str) -> str:
    """生成搜索文本：去除标点和空格"""
    # 去除标点符号
    text = re.sub(r'[，。！？、；：""''【】（）·—]', '', content)
    # 去除空格和换行
    text = text.replace(' ', '').replace('\n', '')
    return text
```

### 5.4 输出目录结构

```
liumo-assets-prep/
├── assets/
│   ├── dist/              # 精选集（已有）
│   ├── full/              # 全量增强版（生成）
│   │   ├── tang_shi_enhanced.json
│   │   ├── song_ci_enhanced.json
│   │   ├── gu_wen_enhanced.json
│   │   └── ...
│   └── ...
└── output/                # 数据库输出
    ├── core.db            # 精选集数据库
    └── full.db.gz         # 全量版数据库（压缩）
```

---

## 六、构建脚本设计 (builder.py)

### 6.1 命令行参数

```python
parser.add_argument('--type', choices=['lite', 'full'], required=True,
                    help='构建类型：lite=精选集，full=全量版')
parser.add_argument('--dist', default='assets/dist/',
                    help='精选集数据目录')
parser.add_argument('--full', default='assets/full/',
                    help='全量版数据目录')
parser.add_argument('--output', default='output/',
                    help='输出目录')
```

### 6.2 核心逻辑

```python
def build_database(db_type: str, data_dir: str, output_path: str):
    """构建 SQLite 数据库"""

    # 1. 创建数据库和表
    conn = create_database(output_path)

    # 2. 加载 JSON 数据
    json_files = glob.glob(f"{data_dir}/*.json")
    all_data = []

    for json_file in json_files:
        with open(json_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
            all_data.extend(data)

    # 3. 写入数据
    for item in all_data:
        conn.execute('''
            INSERT INTO poetry (id, title, author, dynasty, layout_strategy, content_json, tags, search_text)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?)
        ''', (
            item['id'],
            item['title'],
            item['author'],
            item['dynasty'],
            item['layout_strategy'],
            item['content_json'],
            json.dumps(item.get('tags', [])),
            item['search_text']
        ))

    # 4. 全量版特殊处理：重建 FTS 索引（生产环境只读）
    if db_type == 'full':
        conn.execute('INSERT INTO poetry_fts(poetry_fts) VALUES("rebuild")')

    conn.commit()
    conn.close()

    # 5. 压缩（仅全量版）
    if db_type == 'full':
        compress_database(output_path)
```

### 6.3 构建命令

```bash
# 构建精选集
python builder.py --type lite --dist assets/dist/ --output output/core.db

# 构建全量版
python builder.py --type full --dist assets/dist/ --full assets/full/ --output output/full.db
```

---

## 七、Rust 后端架构 (Tauri)

### 7.1 Poetry 结构体

```rust
use serde::{Deserialize, Serialize};

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Poetry {
    pub id: String,
    pub title: String,
    pub author: String,
    pub dynasty: String,
    
    // 排版策略
    pub layout_strategy: String,
    
    // 内容透传（前端负责 JSON.parse）
    pub content_json: String,
    
    // 标签
    pub tags: Option<String>,
    
    // 搜索文本（不序列化给前端）
    #[serde(skip_serializing)]
    pub search_text: String,
}
```

### 7.2 FTS5 搜索命令

```rust
#[tauri::command]
pub fn search_poetry(
    app: AppHandle,
    keyword: String,
    tag_filter: Option<String>,
    offset: i64,
    limit: i64,
) -> Result<Vec<Poetry>, String> {
    let db_path = get_db_path(&app)?;
    let conn = Connection::open(&db_path).map_err(|e| e.to_string())?;
    
    let safe_limit = limit.min(100).max(1);
    
    // 使用 FTS5 进行高效搜索
    let mut query = String::from(r#"
        SELECT p.id, p.title, p.author, p.dynasty,
               p.layout_strategy, p.content_json, p.tags, p.search_text
        FROM poetry p
        JOIN poetry_fts fts ON p.rowid = fts.rowid
        WHERE poetry_fts MATCH ?1
    "#);
    
    if let Some(ref tag) = tag_filter {
        query.push_str(&format!(
            " AND p.tags LIKE '%\"{}\"%'", 
            tag.replace("\"", "")
        ));
    }
    
    query.push_str(" ORDER BY rank LIMIT ?2 OFFSET ?3");
    
    let mut stmt = conn.prepare(&query).map_err(|e| e.to_string())?;
    
    // FTS5 查询语法：支持前缀匹配
    let fts_query = format!("\"{}\"*", keyword);
    
    let rows = stmt.query_map(
        params![fts_query, safe_limit, offset],
        |row| {
            Ok(Poetry {
                id: row.get(0)?,
                title: row.get(1)?,
                author: row.get(2)?,
                dynasty: row.get(3)?,
                layout_strategy: row.get(4)?,
                content_json: row.get(5)?,
                tags: row.get(6)?,
                search_text: row.get(7)?,
            })
        }
    ).map_err(|e| e.to_string())?;
    
    rows.collect::<Result<Vec<_>, _>>().map_err(|e| e.to_string())
}
```

### 7.3 数据库初始化

```rust
fn init_db(app: &AppHandle) -> Result<Connection, String> {
    let db_path = get_db_path(app)?;
    let conn = Connection::open(&db_path).map_err(|e| e.to_string())?;
    
    // 启用 WAL 模式（提升并发性能）
    conn.pragma_update(None, "journal_mode", "WAL")?;
    
    conn.execute_batch(include_str!("schema.sql"))
        .map_err(|e| e.to_string())?;
    
    Ok(conn)
}
```

---

## 八、实施计划

### 8.1 阶段一：数据处理脚本

| 任务 | 说明 | 状态 |
| ---- | ---- | ---- |
| 创建 `assets/full/` 目录 | 存放全量增强数据 | 待办 |
| 编写 `scripts/enhance_raw.py` | 批量处理 raw 文件 | 待办 |
| 处理 tang_shi.json | 清洗 dynasty 和 author | 待办 |
| 处理 song_ci.json | 生成结构化数据 | 待办 |
| 处理 gu_wen.json | 生成结构化数据 | 待办 |
| 处理 qing_wen.json | 特殊格式，暂跳过 | 待办 |

### 8.2 阶段二：构建脚本

| 任务 | 说明 | 状态 |
| ---- | ---- | ---- |
| 更新 `builder.py` | 支持 lite/full 模式 | 待办 |
| 实现 FTS5 触发器 | 自动同步索引 | 待办 |
| 测试 lite 构建 | 验证 core.db | 待办 |
| 测试 full 构建 | 验证 full.db | 待办 |

### 8.3 阶段三：后端 Rust

| 任务 | 说明 | 状态 |
| ---- | ---- | ---- |
| 更新 `db.rs` | 新版 Poetry 结构体 | 待办 |
| 实现 FTS5 搜索 | 高性能检索 | 待办 |
| 删除冗余字段 | content / type_ | 待办 |

### 8.4 阶段四：前端适配

| 任务 | 说明 | 状态 |
| ---- | ---- | ---- |
| 更新类型定义 | 新版 JSON Schema | 待办 |
| 解析 content_json | 前端 JSON.parse | 待办 |
| 删除 fallback 逻辑 | 旧版 content 字段 | 待办 |

---

## 九、风险与应对

| 风险 | 可能性 | 影响 | 应对措施 |
| ---- | ------ | ---- | -------- |
| 脚本处理质量不足 | 中 | 古文分段不准 | 后续根据用户反馈针对性优化 |
| 全量数据过大，构建超时 | 低 | 构建失败 | 分批处理，增量构建 |
| FTS5 索引体积过大 | 低 | 安装包膨胀 | 压缩 full.db.gz |

---

## 十、验收标准

1. **数据一致性**：精选集与全量版数据格式完全统一
2. **功能完整**：支持 GRID_STANDARD / FLOW_VARYING / CENTER_ALIGNED 三种布局
3. **搜索性能**：1000 条数据 FTS5 搜索 < 50ms
4. **构建成功**：lite 构建 < 10s，full 构建 < 5min
5. **前端兼容**：新数据结构能被前端正确解析渲染

---

## 附录 A：文件变更清单

| 操作 | 文件路径 |
| ---- | -------- |
| 新增 | `assets/full/` 目录 |
| 新增 | `scripts/enhance_raw.py` |
| 修改 | `scripts/builder.py` |
| 修改 | `src-tauri/src/db.rs` |
| 删除 | `src-tauri/src/db.rs` 中的旧字段 |

---

## 附录 B：核心脚本伪代码

```python
# enhance_raw.py - 全量数据增强脚本
import json
import hashlib
import re

def main():
    input_dir = "assets/raw"
    output_dir = "assets/full"
    
    for filename in os.listdir(input_dir):
        if not filename.endswith(".json"):
            continue
            
        input_path = f"{input_dir}/{filename}"
        output_path = f"{output_dir}/{filename}"
        
        process_file(input_path, output_path)
        print(f"Processed: {filename}")

def process_file(input_path, output_path):
    with open(input_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    results = []
    for item in data:
        author = clean_author(item.get('author', ''))
        content = normalize_content(item.get('content', []))
        content_json = build_content_json(content)
        layout_strategy = infer_layout_strategy(item.get('type'), content)
        tags = build_tags(item.get('type'))
        search_text = build_search_text(content)
        id = generate_id(item.get('title', ''), author)
        
        results.append({
            "id": id,
            "title": item.get('title', ''),
            "author": author,
            "dynasty": item.get('dynasty', ''),
            "layout_strategy": layout_strategy,
            "content_json": json.dumps(content_json, ensure_ascii=False),
            "tags": tags,
            "search_text": search_text
        })
    
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)

# ... (各函数实现见上文)
```

---

> **审批人**: ____________
> **审批日期**: ____________
> **审批意见**: ____________
